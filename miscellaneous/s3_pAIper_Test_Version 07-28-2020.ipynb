{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "s3_pAIper Test Version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phA4gy64kd1l",
        "colab_type": "text"
      },
      "source": [
        "# pAIper for Google Colab\n",
        "\n",
        "**If you have any questions, don't hesitate to contact Noah at noah@blacksheepfoods.com or 9728166228.**\n",
        "\n",
        "\n",
        "**Instructions:** \n",
        "1. This is a notebook. It allows you to run tiny blocks (\"cells\") of code from your browser.\n",
        "2. You must run the code cells in order (like a Jupyter Notebook)\n",
        "3. For each cell, you can either click the play button to the left of the cell or press Shift + Enter.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trOC8g6zAWJQ",
        "colab_type": "text"
      },
      "source": [
        "# Setting Up\n",
        "Go through the following steps and run the following cells to set up the Black Sheep Foods pAIper repository and its necessary packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQRM34GpArvq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "First, clone (copy) the Black Sheep Foods repository onto this Colab runtime. If you get a \"fatal\" error, ignore it - this just means the repository was already copied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BHakqSzAAbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/bcatoto/bsf.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUzw3hw0mtwz",
        "colab_type": "text"
      },
      "source": [
        "We also need to retrieve the existing models, which are too large to be stored on Github. Run the cell below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Epm9eTm2HE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://paiper-test-1.s3.us-east-2.amazonaws.com/models/dataset1\n",
        "!wget https://paiper-test-1.s3.us-east-2.amazonaws.com/models/dataset1.trainables.syn1neg.npy\n",
        "!wget https://paiper-test-1.s3.us-east-2.amazonaws.com/models/dataset1.wv.vectors.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qti7BsHCusPM",
        "colab_type": "text"
      },
      "source": [
        "Let's now copy the models  to the corresponding bsf directories for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avYJXQe9olsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp dataset1 '/content/bsf/paiper/food2vec/wv'\n",
        "!cp dataset1.trainables.syn1neg.npy '/content/bsf/paiper/food2vec/wv'\n",
        "!cp dataset1.wv.vectors.npy '/content/bsf/paiper/food2vec/wv'\n",
        "print('Files copied.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5SH0SceChfy",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to set the working directory to the `bsf` folder. We will also install all of the necessary packages and data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noqsqkQCCskv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"bsf\")\n",
        "!pip install -r requirements.txt\n",
        "!cde data download\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiAi8usEWZQN",
        "colab_type": "text"
      },
      "source": [
        "# Food2Vec\n",
        "\n",
        "The Food2Vec class uses gensim's [Phrases](https://radimrehurek.com/gensim/models/phrases.html) model to extract phrases from the corpus and gensim's [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) model to form word embeddings from the data. The Food2Vec constructor takes one positional argument, `tag`, which is the label the corresponding Classifier applied to articles when storing it in the MongoDB database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ioUyfR-docO",
        "colab_type": "text"
      },
      "source": [
        "The pretrained phrasers and models should already be loaded in the `paiper/food2vec/phrasers` and `paiper/food2vec/wv` folder. Load `dataset1` by running the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edw6T9Qv2lBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c46e4fb7-3276-4372-c76a-25c501fd3624"
      },
      "source": [
        "from paiper.food2vec import Food2Vec\n",
        "\n",
        "model = Food2Vec('dataset1')\n",
        "model.load_phraser()\n",
        "model.load_wv()\n",
        "print('Model loaded.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0YYT5WNd7n7",
        "colab_type": "text"
      },
      "source": [
        "The `most_similar()` function prints a list of words most similar to the queried word based on the corpus the Word2Vec model is trained on. The function takes two arguments:\n",
        "\n",
        "*   `term`: The query term for which the most similar terms will be returned\n",
        "*   `topn`: Defaults to 1, the number of results  to return\n",
        "\n",
        "There are two optional arguments if you want to add a math-based filter to the results: \n",
        "\n",
        "* `vector_math`: Defaults to False, boolean flag if you want to add a post-processing step. \n",
        "* `closer`: Defaults to empty quotes, one additional term with a positive connotation\n",
        "* `farther`: Defaults to empty quotes, one additional term with a negative connotation\n",
        "\n",
        "You can add and subtract vectors to the initial vector to achieve different results. For instance, if you wanted to find words that were similar to \"flavor\" but close to \"plant\" and far from \"meat\", you could write:\n",
        "```\n",
        "model.most_similar('flavor', vector_math=True, topn=5, closer='plant', farther='meat')\n",
        "```\n",
        "\n",
        "We recommend experimenting with different filter words. Let us know if you get any interesting results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9n66wXpdAU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('flavor', vector_math=True, topn=5, closer='plant', farther='meat')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjrh_IB12ok_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.most_similar('dog', topn=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzg5U3P8eciD",
        "colab_type": "text"
      },
      "source": [
        "The `analogy()` function prints a list of words that complete a given analogy based on the corpus the Word2Vec model is trained on. The format of the analogy as follows:\n",
        "\n",
        "> `same` is to `opp` as `term` is to `analogy()`\n",
        ">\n",
        "> Example: cow is to beef as pig is to what?\n",
        "\n",
        "The function takes three positional arguments and one optional argument:\n",
        "\n",
        "*   `term`: The term to find the corresponding analogy to\n",
        "*   `same`: The term in the given analogy that corresponds to the `term`\n",
        "*   `opp`: The term in the given analogy that corresponds to the resulting term\n",
        "*   `topn`: Defaults to 1, the number of results to return\n",
        "\n",
        "The order of the words is `model.analogy(term, same, opp, # of results you want)`\n",
        "You can think of the order as \"pig is to what as cow is to beef?\" ('pig', 'cow', 'beef', topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLj9pw8O6Z-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.analogy('pig', 'cow', 'beef', topn=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}